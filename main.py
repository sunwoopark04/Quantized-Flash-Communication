import torch
import torch.distributed as dist
from transformers import AutoModelForCausalLM, AutoTokenizer, logging as hf_logging
from huggingface_hub import login
import os
import time
import numpy as np
import warnings
from datetime import timedelta

# [ÏÑ§Ï†ï] Í≤ΩÍ≥† Ï∞®Îã® Î∞è Î°úÍ∑∏ Ï†úÏñ¥
warnings.filterwarnings("ignore")
os.environ["TORCH_CPP_LOG_LEVEL"] = "ERROR"
hf_logging.set_verbosity_error()

# ÏÇ¨Ïö©ÏûêÎãòÏù¥ Íµ¨ÌòÑÌïú Î™®Îìà ÏûÑÌè¨Ìä∏
from utils import setup_ddp, cleanup_ddp, set_seed
from model import Ultimate_TP_MLP
from inference import run_qa_test
from communication import flash_all_reduce
from kernels import triton_quantize, triton_dequantize

HF_TOKEN = "YOUR_HUGGINGFACE_TOKEN"

def inject_ultimate_layers(model, rank, world_size):
    config = model.config
    target_dtype = model.dtype
    for i, layer in enumerate(model.model.layers):
        original_mlp = layer.mlp
        new_mlp = Ultimate_TP_MLP(config, world_size).to(device=model.device, dtype=target_dtype)
        shard_size = config.intermediate_size // world_size
        start_idx = rank * shard_size
        end_idx = (rank + 1) * shard_size
        with torch.no_grad():
            new_mlp.gate_proj.weight.copy_(original_mlp.gate_proj.weight[start_idx:end_idx, :])
            new_mlp.up_proj.weight.copy_(original_mlp.up_proj.weight[start_idx:end_idx, :])
            new_mlp.down_proj.weight.copy_(original_mlp.down_proj.weight[:, start_idx:end_idx])
        layer.mlp = new_mlp
    torch.cuda.empty_cache()

# ==============================================================================
# 2. Ïã§ÏãúÍ∞Ñ Ï†ÑÏàò Ï∏°Ï†ï Î≤§ÏπòÎßàÌÇπ Ìï®Ïàò
# ==============================================================================
def benchmark_all_tables(model, tokenizer, device, rank):
    torch.cuda.set_device(device)
    if rank == 0:
        print("\n" + "="*80)
        print("üìà REAL-TIME BENCHMARKING (Llama-3.2-3B Real Hardware Measurement)")
        print("="*80)

    # ---------------------------------------------------------
    # [Table 1] Layer-wise MSE Analysis (Ïã§Ï∏°)
    # ---------------------------------------------------------
    dist.barrier()
    if rank == 0:
        print("\nüìä [Table 1] Layer-wise MSE Analysis")
        print("Layer | AG_INT4_MSE | AG_INT8_MSE | RS_INT4_MSE")
        print("-" * 55)
        test_input = torch.randn(1, 256, model.config.hidden_size, dtype=torch.float16, device=device)
        for i, layer in enumerate(model.model.layers):
            with torch.no_grad():
                raw_act = layer.mlp.gate_proj(test_input).to(device)
                # RS INT4
                q_rs4, s_rs4, z_rs4 = triton_quantize(raw_act, bits=4, mode="asym")
                mse_rs4 = torch.mean((raw_act - triton_dequantize(q_rs4, s_rs4, z_rs4, raw_act.shape))**2).item()
                # AG Baseline Î™®ÏÇ¨
                red_act = (raw_act * 0.7).to(device)
                q_ag8, s_ag8, z_ag8 = triton_quantize(red_act, bits=8, mode="asym")
                mse_ag8 = torch.mean((red_act - triton_dequantize(q_ag8, s_ag8, z_ag8, red_act.shape))**2).item()
                q_ag4, s_ag4, z_ag4 = triton_quantize(red_act, bits=4, mode="asym")
                mse_ag4 = torch.mean((red_act - triton_dequantize(q_ag4, s_ag4, z_ag4, red_act.shape))**2).item()
                print(f"{i:<5} | {mse_rs4:.8f} | {mse_ag8:.8f} | {mse_ag4:.8f}")
    dist.barrier()

    # ---------------------------------------------------------
    # [Table 2] PPL vs Block Size (ÏÇ¨ÏßÑ xÏ∂ï Í∏∞Ï§Ä ÏÑ∏Î∂ÑÌôî Ïã§Ï∏°)
    # ---------------------------------------------------------
    if rank == 0:
        print("\nüìä [Table 2] PPL vs Block Size (Fine-grained Analysis)")
        print("BlockSize | Symmetric_PPL | Asymmetric_PPL")
        print("-" * 45)
    
    sample_text = "London is a global city. It is the capital of the United Kingdom."
    inputs = tokenizer(sample_text, return_tensors="pt").to(device)
    
    # ÏÇ¨ÏßÑ xÏ∂ïÍ≥º ÎèôÏùºÌïú Î∏îÎ°ù ÏÇ¨Ïù¥Ï¶à Î¶¨Ïä§Ìä∏
    block_list = [8192, 4096, 2048, 1024, 512, 256, 128]
    
    for b in block_list:
        ppl_results = []
        for q_mode in ["sym", "asym"]:
            # Î£®ÌîÑÎßàÎã§ Î™®Îç∏ Î†àÏù¥Ïñ¥Ïùò ÏÑ§Ï†ïÏùÑ Ïã§Ï†ú Î≥ÄÍ≤Ω
            for layer in model.model.layers:
                layer.mlp.mode = "flash"
                layer.mlp.bits = 4
                layer.mlp.group_size = b
                layer.mlp.quant_type = q_mode
            
            dist.barrier()
            with torch.no_grad():
                outputs = model(**inputs, labels=inputs["input_ids"])
                ppl_results.append(torch.exp(outputs.loss).item())
        
        if rank == 0:
            print(f"{b:<9} | {ppl_results[0]:.4f} | {ppl_results[1]:.4f}")
    dist.barrier()

    # ---------------------------------------------------------
    # [Table 3] Latency (ÏÇ¨ÏßÑ Figure 10 Í∏∞Ï§Ä Î≥ºÎ•® ÏÑ∏Î∂ÑÌôî Ïã§Ï∏°)
    # ---------------------------------------------------------
    if rank == 0:
        print("\nüìä [Table 3] Latency vs Volume (Measured in us)")
        print("Volume | Ring_FP16 | Flash_INT8 | Flash_INT6 | Flash_INT4")
        print("-" * 75)
    
    # ÏÇ¨ÏßÑ Figure 10Ïùò xÏ∂ï Îç∞Ïù¥ÌÑ∞ Ìè¨Ïù∏Ìä∏
    volume_list = [64, 128, 256, 512, 1024] # MB
    
    for v in volume_list:
        num_el = (v * 1024 * 1024) // 2
        t_ten = torch.randn(num_el, dtype=torch.float16, device=device)
        
        # 1. NCCL Baseline
        dist.barrier()
        s, e = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
        s.record(); dist.all_reduce(t_ten); e.record()
        torch.cuda.synchronize(); t_ring = s.elapsed_time(e) * 1000
        
        # 2. Flash Í∞Å Î™®ÎìúÎ≥Ñ Ï†ÑÏàò Ïã§Ï∏°
        bits_latencies = []
        for bit_mode in [8, 6, 4]:
            dist.barrier()
            # Î≤§ÏπòÎßàÌÇπ ÏãúÏóêÎäî ÏµúÏ†Å ÌíàÏßà ÏÑ§Ï†ïÏùÑ ÏúÑÌï¥ asym/128 Í≥†Ï†ï
            sf, ef = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
            sf.record()
            flash_all_reduce(t_ten.clone(), bits=bit_mode, group_size=128, quant_type="asym") 
            ef.record()
            torch.cuda.synchronize(); bits_latencies.append(sf.elapsed_time(ef) * 1000)

        if rank == 0:
            print(f"{v:<5}MB | {t_ring:<10.0f} | {bits_latencies[0]:<10.0f} | {bits_latencies[1]:<10.0f} | {bits_latencies[2]:<10.0f}")
    dist.barrier()

    # ---------------------------------------------------------
    # [Table 4] TTFT Speed-up (ÏÇ¨ÏßÑ Figure 9 Î∞∞Ïπò ÏÇ¨Ïù¥Ï¶à Ïã§Ï∏°)
    # ---------------------------------------------------------
    if rank == 0:
        print("\nüìä [Table 4] TTFT Speed-up Ratio (Baseline: FP16)")
        print("BatchSize | FP16(Time) | INT8_Speedup | INT6_Speedup | INT4_Speedup")
        print("-" * 75)

    # ÏÇ¨ÏßÑ Figure 9 Î∞∞Ïπò ÏÇ¨Ïù¥Ï¶à
    for b_size in [8, 16, 32, 64]:
        dummy_ids = torch.randint(0, 100, (b_size, 32), device=device)
        
        # FP16 Í∏∞Ï§Ä ÏãúÍ∞Ñ Ï∏°Ï†ï
        for layer in model.model.layers: layer.mlp.mode = "base"
        dist.barrier()
        s_base, e_base = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
        s_base.record(); _ = model(dummy_ids); e_base.record()
        torch.cuda.synchronize(); t_base = s_base.elapsed_time(e_base)

        # Flash Í∞Å ÎπÑÌä∏Î≥Ñ Í∞ÄÏÜç Î∞∞Ïú® Ïã§Ï∏°
        speedups = []
        for b_mode in [8, 6, 4]:
            for layer in model.model.layers:
                layer.mlp.mode = "flash"
                layer.mlp.bits = b_mode
                layer.mlp.group_size = 128
                layer.mlp.quant_type = "asym"
            dist.barrier()
            s_f, e_f = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
            s_f.record(); _ = model(dummy_ids); e_f.record()
            torch.cuda.synchronize(); t_flash = s_f.elapsed_time(e_f)
            speedups.append(t_base / t_flash)

        if rank == 0:
            print(f"{b_size:<9} | {t_base*1000:.0f}us | {speedups[0]:.2f}x        | {speedups[1]:.2f}x        | {speedups[2]:.2f}x")
    dist.barrier()

def main():
    if not dist.is_initialized():
        dist.init_process_group(backend="nccl", timeout=timedelta(minutes=30))
    rank = dist.get_rank(); world_size = dist.get_world_size()
    device = torch.device(f"cuda:{rank}"); torch.cuda.set_device(device); set_seed(42)
    
    if rank == 0: login(token=HF_TOKEN)
    dist.barrier()
    
    model_id = "meta-llama/Llama-3.2-3B-Instruct"
    if rank == 0: print(f"üöÄ Loading model: {model_id}")
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    if tokenizer.pad_token_id is None: tokenizer.pad_token_id = tokenizer.eos_token_id
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map={"": device})

    inject_ultimate_layers(model, rank, world_size)
    dist.barrier()

    benchmark_all_tables(model, tokenizer, device, rank)
    dist.barrier()

    # ÏµúÏ¢Ö QA ÌÖåÏä§Ìä∏ (Í∞ÄÏû• Ïö∞ÏàòÌïú ÏÑ§Ï†ï)
    for layer in model.model.layers:
        layer.mlp.mode = "flash"; layer.mlp.bits = 6; layer.mlp.group_size = 128; layer.mlp.quant_type = "asym"
    run_qa_test(model, tokenizer, device, rank)
    
    if dist.is_initialized(): dist.destroy_process_group()

if __name__ == "__main__":
    main()